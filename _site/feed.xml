<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2018-08-25T23:35:35-04:00</updated><id>http://localhost:4000/</id><title type="html">Parker Lawrence portfolio</title><subtitle>Parker Lawrence's portfolio website and blog about interesting topics. If you're working on similar projects or you know Parker Lawrence, you may find this site interesting.</subtitle><entry><title type="html">Voxel Level of Detail</title><link href="http://localhost:4000/voxel/2018/08/13/voxel-level-of-detail.html" rel="alternate" type="text/html" title="Voxel Level of Detail" /><published>2018-08-13T10:39:54-04:00</published><updated>2018-08-13T10:39:54-04:00</updated><id>http://localhost:4000/voxel/2018/08/13/voxel-level-of-detail</id><content type="html" xml:base="http://localhost:4000/voxel/2018/08/13/voxel-level-of-detail.html">&lt;p&gt;
Games typically put more detail close to the player and less detail further away. This ensures the game runs smoothly, because less triangles need to be rendered if they occupy a small space on the screen. This concept is called level of detail (or LOD). Game developers forfeit their direct control over level of detail when they make their game a voxel game, but they can get around this by designing a system that can turn volumetric data into a visible mesh with a specified level of detail. The figure below shows meshes generated from the same volumetric data but different levels of detail in 2D.
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/vox/chapter3/figure1.png&quot; alt=&quot;figure 1&quot; /&gt;&lt;/p&gt;
&lt;p&gt;
Generating a less detailed mesh isn’t terribly difficult. Each branch of the octree must store a vertex, just like the leaves do. Then, each branch with a depth X above the leaves become the new leaves, so that when the mesh generation step occurs, each 2x2x2 region behaves as one feature. In the leaves of the tree, Vertices are placed by minimizing Q(x,y,z), the sum of the squared distance to each nearby tangent plane. When grouping regions together, then, the branch must minimize the sum of each child node’s Q function. This allows vertex calculation to be done for all levels of detail recursively.
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/vox/chapter3/figure2.png&quot; alt=&quot;figure 2&quot; /&gt;&lt;/p&gt;
&lt;p&gt;
The difficult part comes when polygons must be drawn to stitch together different levels of detail. Enclosed are diagrams and examples of cases that must be handled. Extra triangles must be drawn to ensure the mesh is continuous, but that can be very difficult. Even worse, though, is that any time the level of detail on one chunk must be changed, that could result to tiny changes in the edges of up to six other meshes, requiring full recalculation of each. I solve this problem by storing the main part of the chunk separately from the skirting. The main mesh is generated in each level of detail and does not recalculate unless changed, while the skirt is recalculated each time it or one of its six relevant neighbors are changed. The skirt alone takes much less time to recalculate, and this way level of detail recalculation is minimized. The game can also load a lot more terrain before performance takes a hit, due to level of detail.
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/vox/chapter3/figure3.png&quot; alt=&quot;figure 3&quot; /&gt;&lt;/p&gt;
&lt;p&gt;
There are many other optimizations done to the game to increase performance. One of which is VBO indexing. This can decrease graphics card memory used for any application, but with dual contouring, it offers an additional benefit. Stitching between vertecies must be recalculated only when the gridlike sampling points change, but the index array does not change when hermit data changes. This means, for small changes to terrain, only part of the mesh generation must be recalculated. 
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/vox/chapter3/figure4.png&quot; alt=&quot;figure 4&quot; /&gt;&lt;/p&gt;
&lt;p&gt;
Another optimization (and by far the simplest) is called frustrum culling. The game does not need to render meshes that are outside the camera’s view, so if the game can quickly detect this, many costly draw calls can be avoided. The detection method may have false negatives, but false positives are unacceptable, because then meshes would disappear from the players view. The voxel engine does this by first extracting the top, bottom, left, right, near, and far planes from the camera’s projection matrix, and then testing if the bounding spheres of meshes lies inside those six planes. The math behind this isn’t hard- it boils down to just six dot products, some addition, and some comparison per bounding sphere. It can be tricky to debug, though, because if all is working well, the only noticeable difference is performance. 
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/vox/chapter3/figure5.png&quot; alt=&quot;figure 5&quot; /&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">Games typically put more detail close to the player and less detail further away. This ensures the game runs smoothly, because less triangles need to be rendered if they occupy a small space on the screen. This concept is called level of detail (or LOD). Game developers forfeit their direct control over level of detail when they make their game a voxel game, but they can get around this by designing a system that can turn volumetric data into a visible mesh with a specified level of detail. The figure below shows meshes generated from the same volumetric data but different levels of detail in 2D. Generating a less detailed mesh isn’t terribly difficult. Each branch of the octree must store a vertex, just like the leaves do. Then, each branch with a depth X above the leaves become the new leaves, so that when the mesh generation step occurs, each 2x2x2 region behaves as one feature. In the leaves of the tree, Vertices are placed by minimizing Q(x,y,z), the sum of the squared distance to each nearby tangent plane. When grouping regions together, then, the branch must minimize the sum of each child node’s Q function. This allows vertex calculation to be done for all levels of detail recursively. The difficult part comes when polygons must be drawn to stitch together different levels of detail. Enclosed are diagrams and examples of cases that must be handled. Extra triangles must be drawn to ensure the mesh is continuous, but that can be very difficult. Even worse, though, is that any time the level of detail on one chunk must be changed, that could result to tiny changes in the edges of up to six other meshes, requiring full recalculation of each. I solve this problem by storing the main part of the chunk separately from the skirting. The main mesh is generated in each level of detail and does not recalculate unless changed, while the skirt is recalculated each time it or one of its six relevant neighbors are changed. The skirt alone takes much less time to recalculate, and this way level of detail recalculation is minimized. The game can also load a lot more terrain before performance takes a hit, due to level of detail. There are many other optimizations done to the game to increase performance. One of which is VBO indexing. This can decrease graphics card memory used for any application, but with dual contouring, it offers an additional benefit. Stitching between vertecies must be recalculated only when the gridlike sampling points change, but the index array does not change when hermit data changes. This means, for small changes to terrain, only part of the mesh generation must be recalculated. Another optimization (and by far the simplest) is called frustrum culling. The game does not need to render meshes that are outside the camera’s view, so if the game can quickly detect this, many costly draw calls can be avoided. The detection method may have false negatives, but false positives are unacceptable, because then meshes would disappear from the players view. The voxel engine does this by first extracting the top, bottom, left, right, near, and far planes from the camera’s projection matrix, and then testing if the bounding spheres of meshes lies inside those six planes. The math behind this isn’t hard- it boils down to just six dot products, some addition, and some comparison per bounding sphere. It can be tricky to debug, though, because if all is working well, the only noticeable difference is performance.</summary></entry><entry><title type="html">Voxel Data Visualization</title><link href="http://localhost:4000/voxel/2018/08/13/voxel-data-visualization.html" rel="alternate" type="text/html" title="Voxel Data Visualization" /><published>2018-08-13T10:39:54-04:00</published><updated>2018-08-13T10:39:54-04:00</updated><id>http://localhost:4000/voxel/2018/08/13/voxel-data-visualization</id><content type="html" xml:base="http://localhost:4000/voxel/2018/08/13/voxel-data-visualization.html">&lt;p&gt;
The first thing needed for a voxel engine is called an isosurface. An isosurface is a multidimensional function where negative values are intended to be outside the ‘solid’ and positive values are intended to be inside the solid. Interesting ones that resemble roads, mountains, and valleys can come later, but right now simple isosurfaces like spheres and planes are useful for testing. Isosurfaces are only used to generate the initial terrain- once generated, the terrain can be changed to no longer resemble the function. Isosurface functions only need to be fast to execute- they need not have a known derivative, integral, or any other property. Rather, they are sampled. The function is called at every 3d gridpoint in the game world, with the assumption that for each two points, if one is positive and the other negative, the solid has boundary that exists between those so points. Isosurfaces are useful for the voxel engine because they are very flexible, so most generation is done using them.
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/vox/chapter1/figure1.png&quot; alt=&quot;figure 1&quot; /&gt;&lt;/p&gt;
&lt;p&gt;
The second thing needed for a voxel engine is a method to turn volumetric data into a visible mesh. The simplest way to do this is intuitive: create a square on each boundary between transparent and opaque material. The isosurface must be sampled at each 3d gridpoint, and then this data must be remembered. This is the method most are familiar with, thanks to Minecraft. This is a very fast approach that makes texturing easy, but the results are always blocky.
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/vox/chapter1/figure2.png&quot; alt=&quot;figure 2&quot; /&gt;&lt;/p&gt;
&lt;p&gt;
The second method, which I also experimented with, is called marching cubes. Marching cubes places all vertices along the line segments connecting the sampling points, and stitches polygons between them according to a lookup table with the opaqueness of the surrounding vertices. To use this method, the program must make an estimate at where boundary of an isosurface lies, given two points, one above zero, one below zero. This is done linearly. The figure below illustrates this in 2D with four vertices and 16 entries in the lookup table, but the concept extends to 3D where eight vertices would be considered with 256 entries in the table. Marching cubes is most commonly used in medical imaging. It produces only smooth meshes (or at least beveled meshes) This is an improvement, because the voxel boundary has another degree of freedom- vertices can be placed anywhere on the line segment between the two sampling points, allowing for ground that isn’t perfectly even.
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/vox/chapter1/figure3.png&quot; alt=&quot;figure 3&quot; /&gt;&lt;/p&gt;
&lt;p&gt;
The extra degree of freedom is nice, but not perfect- The ability to have sharp corners is sacrificed, but the smoother meshes aren’t perfectly smooth, either. The last method is dual contouring: the Cadillac of isosurface extraction algorithms. The distance along the line segment between sample points must be known, same as marching cubes, but this time the vector perpendicular to the isosurface at that point much also be known. This is called hermitian data, and in addition to the linear method used to estimate the position of the boundary, six extra calls to the sampling function are used to estimate the vector perpendicular to the surface at a given point, which is called the normal. Vertices are then placed inside each box at the location that minimizes the sum of squared distances to each surrounding tangent plane. Then, stitching between vertices is done exactly like in method 1, no lookup table needed. Specifying normal information allows for both smooth and sharp meshes (and everything in between). This is how voxel games break out of their blocky, axis aligned shells.
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/vox/chapter1/figure4.png&quot; alt=&quot;figure 4&quot; /&gt;&lt;/p&gt;
&lt;p&gt;
Minimizing the squared distance to each tangent plane is a difficult process, but having a little knowledge of multi variable calculus makes things a lot easier. The figure below shows the specific math involved. The nine coefficients for each tangent plane are summed up and then turned into a 3x3 matrix which is solved to get the vertex. I’ve seen people take the pseudo inverse of a matrix with those coefficients with svd decomposition but I’ve gotten better results without that.
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/vox/chapter1/figure5.png&quot; alt=&quot;figure 5&quot; /&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">The first thing needed for a voxel engine is called an isosurface. An isosurface is a multidimensional function where negative values are intended to be outside the ‘solid’ and positive values are intended to be inside the solid. Interesting ones that resemble roads, mountains, and valleys can come later, but right now simple isosurfaces like spheres and planes are useful for testing. Isosurfaces are only used to generate the initial terrain- once generated, the terrain can be changed to no longer resemble the function. Isosurface functions only need to be fast to execute- they need not have a known derivative, integral, or any other property. Rather, they are sampled. The function is called at every 3d gridpoint in the game world, with the assumption that for each two points, if one is positive and the other negative, the solid has boundary that exists between those so points. Isosurfaces are useful for the voxel engine because they are very flexible, so most generation is done using them. The second thing needed for a voxel engine is a method to turn volumetric data into a visible mesh. The simplest way to do this is intuitive: create a square on each boundary between transparent and opaque material. The isosurface must be sampled at each 3d gridpoint, and then this data must be remembered. This is the method most are familiar with, thanks to Minecraft. This is a very fast approach that makes texturing easy, but the results are always blocky. The second method, which I also experimented with, is called marching cubes. Marching cubes places all vertices along the line segments connecting the sampling points, and stitches polygons between them according to a lookup table with the opaqueness of the surrounding vertices. To use this method, the program must make an estimate at where boundary of an isosurface lies, given two points, one above zero, one below zero. This is done linearly. The figure below illustrates this in 2D with four vertices and 16 entries in the lookup table, but the concept extends to 3D where eight vertices would be considered with 256 entries in the table. Marching cubes is most commonly used in medical imaging. It produces only smooth meshes (or at least beveled meshes) This is an improvement, because the voxel boundary has another degree of freedom- vertices can be placed anywhere on the line segment between the two sampling points, allowing for ground that isn’t perfectly even. The extra degree of freedom is nice, but not perfect- The ability to have sharp corners is sacrificed, but the smoother meshes aren’t perfectly smooth, either. The last method is dual contouring: the Cadillac of isosurface extraction algorithms. The distance along the line segment between sample points must be known, same as marching cubes, but this time the vector perpendicular to the isosurface at that point much also be known. This is called hermitian data, and in addition to the linear method used to estimate the position of the boundary, six extra calls to the sampling function are used to estimate the vector perpendicular to the surface at a given point, which is called the normal. Vertices are then placed inside each box at the location that minimizes the sum of squared distances to each surrounding tangent plane. Then, stitching between vertices is done exactly like in method 1, no lookup table needed. Specifying normal information allows for both smooth and sharp meshes (and everything in between). This is how voxel games break out of their blocky, axis aligned shells. Minimizing the squared distance to each tangent plane is a difficult process, but having a little knowledge of multi variable calculus makes things a lot easier. The figure below shows the specific math involved. The nine coefficients for each tangent plane are summed up and then turned into a 3x3 matrix which is solved to get the vertex. I’ve seen people take the pseudo inverse of a matrix with those coefficients with svd decomposition but I’ve gotten better results without that.</summary></entry><entry><title type="html">Voxel Data Storage</title><link href="http://localhost:4000/voxel/2018/08/13/voxel-data-storage.html" rel="alternate" type="text/html" title="Voxel Data Storage" /><published>2018-08-13T10:39:54-04:00</published><updated>2018-08-13T10:39:54-04:00</updated><id>http://localhost:4000/voxel/2018/08/13/voxel-data-storage</id><content type="html" xml:base="http://localhost:4000/voxel/2018/08/13/voxel-data-storage.html">&lt;p&gt;
Data storage is the second challenge to overcome. If the game has a reasonable, fixed size, and you can afford to store all data at once, you might as well just store it in a large 3D array. Geometrically, each element in the 3 dimensional array represents a 1x1x1 area.
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/vox/chapter2/figure1.png&quot; alt=&quot;figure 1&quot; /&gt;&lt;/p&gt;
&lt;p&gt;
More often, though, you’ll either want the map size to be infinite or at least large enough that you can’t store all of that information at once. For that, you’ll need to break the map apart into reasonably sized pieces that can be read from and written to memory. There is often a bit of nuance with regards to threading and ensuring that you only attempt to generate mesh for a chunk when its neighbors are loaded too. There is always mesh data along the edge of each chunk that cannot be generated without data from other chunks. This is sometimes referred to as the skirt, which usually has some unique considerations, especially when threading is involved. Each element in each 3 dimensional array is still responsible for a 1x1x1 volume, but additionally, each chunk is responsible for a larger defined volume as well.
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/vox/chapter2/figure2.png&quot; alt=&quot;figure 2&quot; /&gt;&lt;/p&gt;
&lt;p&gt;
For very fine voxel resolutions, you’ll want to construct an octree. An octree is a recursive structure where 3D space is recursively subdivided into 8 regions. Any area that is one solid type of voxel does not need to be subdivided and is stored as one id. As you can see in the figure, for finer resolutions, there is a significant reduction in memory usage. The octree offers this reduction because volumetric data often has large, contiguous, homogenous areas. Now that our volumetric data is stored as a tree, we should access it similarly to doing a binary search. The figure below provides a visual explanation of why we can use the binary representation of the block’s coordinates to get its place in the tree. Reading from and writing to a file is still trivial- the octree must be saved recursively.
The octree has restrictions on it that allow it to function. The octree always has a ‘bottom’, where it will not divide area any further. Branches must know how far they are above this bottom- this will determine if they are accountable for a 2x2x2 volume, a 4x4x4 volume, an 8x8x8 volume, etc. Branches will always be accountable for cubic volume whose side lengths are a power of two above one. Solid areas that are not subdivided are stored as buds, which are the same but there can be 1x1x1 sized buds. (Other tree structures for storing different kinds of data will always be size 1x1x1).
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/vox/chapter2/figure3.png&quot; alt=&quot;figure 3&quot; /&gt;&lt;/p&gt;
&lt;p&gt;
In order to use an octree with an infinite world size, the last two methods can be combined- data is loaded and unloaded in portions with an octree representation. Instead of having an octree for each chunk, though, it’s faster to combine all of the octrees into one octree that expands as more data is loaded in. Without negative values, it’s easy to see how this would work. The tree representing some chunk is loaded, and then must be inserted into the world tree. First, the world tree must grow large enough to encapsulate the area inhabited by the chunk. Growing an octree is done by creating a new root node whose children consist of seven buds and the previous root node. The previous root node will be the lower left child, which ensures that the octree will expand up and to the right. The new root node will be twice as large in each dimension. Then, the tree must recursively divide the appropriate bud until there is a spot for the chunk to be placed. To divide a bud, the bud is replaced with a branch of the same size whose children are smaller buds. Only then can the chunk be placed in the world tree.
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/vox/chapter2/figure4.png&quot; alt=&quot;figure 4&quot; /&gt;&lt;/p&gt;
&lt;p&gt;
To allow for negative values, a change must be made to the octree. When the tree expands, it has to expand in the negative direction as well as the positive direction. To accomplish this, the octree will alternate between making the old root node the new root node’s lower left child and making it the new root node’s upper right child. Geometrically speaking, the octree alternates between doubling forward and doubling backward. This is an extremely effective method for encapsulating all of space, but it makes finding locations in the tree more difficult. 
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/vox/chapter2/figure5.png&quot; alt=&quot;figure 5&quot; /&gt;&lt;/p&gt;
&lt;p&gt;
A voxel’s location in the tree is no longer the same as its binary representation. Relying on the binary representation of the number to ‘wrap around’ would be unacceptable because it would cause discontinuities once the tree expands and begins taking the next most significant bit into consideration. The coordinates of each voxel must be transformed into ‘address space’ before their binary representations may be used to find its position in the tree. This transformation can be observed to be associative with addition (voxels have different addresses but consecutive addresses are still consecutive), which means to transform into address space is to add a certain offset to the coordinate and then take the binary representation. That offset should be 0 in address space, which logically I know has to be the repeating binary pattern 10101010.... Because the tree alternates between expanding positively and negatively, alternating between going down the left side of the tree and the right side will eventually end up at zero. I use a slight modification to this that ensures that chunk coordinates can be found by truncated division by the chunk size. 
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/vox/chapter2/figure6.png&quot; alt=&quot;figure 6&quot; /&gt;&lt;/p&gt;
&lt;p&gt;
The tree can also be used to store hermitian data, but some small changes should be made. In addition to branches, for areas that contain changes, and buds, for uniform areas, There should also be features for areas that need to store a vertex and leaves for areas that need to store edges. As opposed to branches and buds, features and leaves are always size 1x1x1. The following diagram shows the inheritance tree or these structures.
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/vox/chapter2/figure7.png&quot; alt=&quot;figure 7&quot; /&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">Data storage is the second challenge to overcome. If the game has a reasonable, fixed size, and you can afford to store all data at once, you might as well just store it in a large 3D array. Geometrically, each element in the 3 dimensional array represents a 1x1x1 area. More often, though, you’ll either want the map size to be infinite or at least large enough that you can’t store all of that information at once. For that, you’ll need to break the map apart into reasonably sized pieces that can be read from and written to memory. There is often a bit of nuance with regards to threading and ensuring that you only attempt to generate mesh for a chunk when its neighbors are loaded too. There is always mesh data along the edge of each chunk that cannot be generated without data from other chunks. This is sometimes referred to as the skirt, which usually has some unique considerations, especially when threading is involved. Each element in each 3 dimensional array is still responsible for a 1x1x1 volume, but additionally, each chunk is responsible for a larger defined volume as well. For very fine voxel resolutions, you’ll want to construct an octree. An octree is a recursive structure where 3D space is recursively subdivided into 8 regions. Any area that is one solid type of voxel does not need to be subdivided and is stored as one id. As you can see in the figure, for finer resolutions, there is a significant reduction in memory usage. The octree offers this reduction because volumetric data often has large, contiguous, homogenous areas. Now that our volumetric data is stored as a tree, we should access it similarly to doing a binary search. The figure below provides a visual explanation of why we can use the binary representation of the block’s coordinates to get its place in the tree. Reading from and writing to a file is still trivial- the octree must be saved recursively. The octree has restrictions on it that allow it to function. The octree always has a ‘bottom’, where it will not divide area any further. Branches must know how far they are above this bottom- this will determine if they are accountable for a 2x2x2 volume, a 4x4x4 volume, an 8x8x8 volume, etc. Branches will always be accountable for cubic volume whose side lengths are a power of two above one. Solid areas that are not subdivided are stored as buds, which are the same but there can be 1x1x1 sized buds. (Other tree structures for storing different kinds of data will always be size 1x1x1). In order to use an octree with an infinite world size, the last two methods can be combined- data is loaded and unloaded in portions with an octree representation. Instead of having an octree for each chunk, though, it’s faster to combine all of the octrees into one octree that expands as more data is loaded in. Without negative values, it’s easy to see how this would work. The tree representing some chunk is loaded, and then must be inserted into the world tree. First, the world tree must grow large enough to encapsulate the area inhabited by the chunk. Growing an octree is done by creating a new root node whose children consist of seven buds and the previous root node. The previous root node will be the lower left child, which ensures that the octree will expand up and to the right. The new root node will be twice as large in each dimension. Then, the tree must recursively divide the appropriate bud until there is a spot for the chunk to be placed. To divide a bud, the bud is replaced with a branch of the same size whose children are smaller buds. Only then can the chunk be placed in the world tree. To allow for negative values, a change must be made to the octree. When the tree expands, it has to expand in the negative direction as well as the positive direction. To accomplish this, the octree will alternate between making the old root node the new root node’s lower left child and making it the new root node’s upper right child. Geometrically speaking, the octree alternates between doubling forward and doubling backward. This is an extremely effective method for encapsulating all of space, but it makes finding locations in the tree more difficult. A voxel’s location in the tree is no longer the same as its binary representation. Relying on the binary representation of the number to ‘wrap around’ would be unacceptable because it would cause discontinuities once the tree expands and begins taking the next most significant bit into consideration. The coordinates of each voxel must be transformed into ‘address space’ before their binary representations may be used to find its position in the tree. This transformation can be observed to be associative with addition (voxels have different addresses but consecutive addresses are still consecutive), which means to transform into address space is to add a certain offset to the coordinate and then take the binary representation. That offset should be 0 in address space, which logically I know has to be the repeating binary pattern 10101010.... Because the tree alternates between expanding positively and negatively, alternating between going down the left side of the tree and the right side will eventually end up at zero. I use a slight modification to this that ensures that chunk coordinates can be found by truncated division by the chunk size. The tree can also be used to store hermitian data, but some small changes should be made. In addition to branches, for areas that contain changes, and buds, for uniform areas, There should also be features for areas that need to store a vertex and leaves for areas that need to store edges. As opposed to branches and buds, features and leaves are always size 1x1x1. The following diagram shows the inheritance tree or these structures.</summary></entry><entry><title type="html">Voxel Continuity Algorithm</title><link href="http://localhost:4000/voxel/2018/08/13/voxel-continuity-algorithm.html" rel="alternate" type="text/html" title="Voxel Continuity Algorithm" /><published>2018-08-13T10:39:54-04:00</published><updated>2018-08-13T10:39:54-04:00</updated><id>http://localhost:4000/voxel/2018/08/13/voxel-continuity-algorithm</id><content type="html" xml:base="http://localhost:4000/voxel/2018/08/13/voxel-continuity-algorithm.html">&lt;p&gt;
Besides performance optimization, there are still things to do to enhance the voxel engine. One thing that voxel engines rarely do (though voxel farm does) is identify any structures that are not attached to the main structure and break them off into their own coordinate system so that they can obey a physics engine and fall. Having multiple coordinate systems is no problem at all- each coordinate system has a separate octree and a transform matrix. The real challenge is identifying disconnected volumes.
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/vox/chapter4/figure1.png&quot; alt=&quot;figure 1&quot; /&gt;&lt;/p&gt;
&lt;p&gt;
The naive solution would be to attempt to pathfind from some point to each other solid voxel, which isn’t a viable solution because it would take forever.
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/vox/chapter4/figure2.png&quot; alt=&quot;figure 2&quot; /&gt;&lt;/p&gt;
&lt;p&gt;
For the vast majority of cases, the octree structure can provide a crucial advantage. First, information about connectivity must be calculated and stored in a bitmask on each branch. This information would include whether the branch contains solid mass and whether that mass is contiguous to the mass of the branches neighboring it in each direction. The calculation is recursive, simple, and fast. 
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/vox/chapter4/figure3.png&quot; alt=&quot;figure 3&quot; /&gt;&lt;/p&gt;
&lt;p&gt;
Next, the octree is recursively checked for continuity with the following rules:
First, check all subtrees for continuity with the recursive step. After this, it can be assumed that all subtrees will be continuous, because if and when any children fail, a piece of the octree will break off into its own coordinate system, and its parent (this node) will be recalculated.
Next, see if the eight subtrees are continuous to each other, without considering any neighbors besides the eight. If they are, the test is passed. If they cannot be proven to be continuous or discontinuous without considering neighboring cells, the tree and its depth are added to a registry.
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/vox/chapter4/figure4.png&quot; alt=&quot;figure 4&quot; /&gt;&lt;/p&gt;
&lt;p&gt;
Outside of the recursion, consider each tree in the registry, smallest depth first. Using a symmetric A* algorithm, the program attempts to pathfind through neighboring cells of the same depth to test continuity.
&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;
	If a path is found, the tree is removed from the registry.
	&lt;img src=&quot;http://localhost:4000/assets/vox/chapter4/figure5.png&quot; /&gt;
	&lt;/li&gt;
	&lt;li&gt;
	If the A* algorithm runs out of open nodes, the side that ran out of open nodes must separate into a new coordinate system, and that tree’s parent node is added to the registry.
	&lt;img src=&quot;http://localhost:4000/assets/vox/chapter4/figure6.png&quot; /&gt;
	&lt;/li&gt;
	&lt;li&gt;
	If the A* algorithm attempts to add a cell that is in an unloaded chunk or in the registry to the open list, then the search is stopped and the node remains in the registry, for the program has not loaded enough data to determine continuity yet. The registry is revisited anytime a chunk loads in or when a chunk is checked for disconnected volumes.
	&lt;img src=&quot;http://localhost:4000/assets/vox/chapter4/figure7.png&quot; /&gt;
	&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
This approach is extremely efficient for a number of reasons. First, it naturally filters out the ‘easy cases’ before they even get to the registry. Easy cases are the ones where the subtrees are continuous without needing to consider neighboring cells. Almost all cases are easy cases, so it’s good that they can be handled with just a handful of bitwise operations. Second, path finding can be done at a higher level than on a block-per-block basis. This figure demonstrates what I mean and the difference this can make. Third, even when all else fails, symmetric A* is able to finish very fast for this use case.
&lt;p&gt;
&lt;/p&gt;
This algorithm also has very natural tie-ins for the rest of the game. Detecting when trees should stay in the registry until chunks load in is an enormous luxury, because it vastly reduces the number of paranoid recalculation that would have to be done if the program could not make this distinction. Also, when the symmetric A* runs out of open nodes and a floating island is identified, the closed list can be used as an exact itinerary for what parts of the octree must be replaced with air and moved into their own octree. The whole strategy is a great example of elegance in programming.
&lt;/p&gt;</content><author><name></name></author><summary type="html">Besides performance optimization, there are still things to do to enhance the voxel engine. One thing that voxel engines rarely do (though voxel farm does) is identify any structures that are not attached to the main structure and break them off into their own coordinate system so that they can obey a physics engine and fall. Having multiple coordinate systems is no problem at all- each coordinate system has a separate octree and a transform matrix. The real challenge is identifying disconnected volumes. The naive solution would be to attempt to pathfind from some point to each other solid voxel, which isn’t a viable solution because it would take forever. For the vast majority of cases, the octree structure can provide a crucial advantage. First, information about connectivity must be calculated and stored in a bitmask on each branch. This information would include whether the branch contains solid mass and whether that mass is contiguous to the mass of the branches neighboring it in each direction. The calculation is recursive, simple, and fast. Next, the octree is recursively checked for continuity with the following rules: First, check all subtrees for continuity with the recursive step. After this, it can be assumed that all subtrees will be continuous, because if and when any children fail, a piece of the octree will break off into its own coordinate system, and its parent (this node) will be recalculated. Next, see if the eight subtrees are continuous to each other, without considering any neighbors besides the eight. If they are, the test is passed. If they cannot be proven to be continuous or discontinuous without considering neighboring cells, the tree and its depth are added to a registry. Outside of the recursion, consider each tree in the registry, smallest depth first. Using a symmetric A* algorithm, the program attempts to pathfind through neighboring cells of the same depth to test continuity. If a path is found, the tree is removed from the registry. If the A* algorithm runs out of open nodes, the side that ran out of open nodes must separate into a new coordinate system, and that tree’s parent node is added to the registry. If the A* algorithm attempts to add a cell that is in an unloaded chunk or in the registry to the open list, then the search is stopped and the node remains in the registry, for the program has not loaded enough data to determine continuity yet. The registry is revisited anytime a chunk loads in or when a chunk is checked for disconnected volumes. This approach is extremely efficient for a number of reasons. First, it naturally filters out the ‘easy cases’ before they even get to the registry. Easy cases are the ones where the subtrees are continuous without needing to consider neighboring cells. Almost all cases are easy cases, so it’s good that they can be handled with just a handful of bitwise operations. Second, path finding can be done at a higher level than on a block-per-block basis. This figure demonstrates what I mean and the difference this can make. Third, even when all else fails, symmetric A* is able to finish very fast for this use case. This algorithm also has very natural tie-ins for the rest of the game. Detecting when trees should stay in the registry until chunks load in is an enormous luxury, because it vastly reduces the number of paranoid recalculation that would have to be done if the program could not make this distinction. Also, when the symmetric A* runs out of open nodes and a floating island is identified, the closed list can be used as an exact itinerary for what parts of the octree must be replaced with air and moved into their own octree. The whole strategy is a great example of elegance in programming.</summary></entry><entry><title type="html">Understanding Rubik’s Puzzles</title><link href="http://localhost:4000/puzzle/2018/08/13/understanding-rubiks-puzzles.html" rel="alternate" type="text/html" title="Understanding Rubik's Puzzles" /><published>2018-08-13T10:39:54-04:00</published><updated>2018-08-13T10:39:54-04:00</updated><id>http://localhost:4000/puzzle/2018/08/13/understanding-rubiks-puzzles</id><content type="html" xml:base="http://localhost:4000/puzzle/2018/08/13/understanding-rubiks-puzzles.html">&lt;p&gt;
In order to build an expressive and powerful simulator, the components that differentiate twisting puzzles must be understood.
First of all, puzzles are usually regular polyhedra. Puzzles that are spherical or especially irregular are outside the scope of this simulator. 
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/puzzle/chapter1/figure1.png&quot; alt=&quot;figure 1&quot; /&gt;
&lt;img src=&quot;http://localhost:4000/assets/puzzle/chapter1/screenshot1.png&quot; alt=&quot;screencap 1&quot; /&gt;&lt;/p&gt;
&lt;p&gt;
Secondly, puzzles are typically either face-turning, edge-turning, or vertex-turning. The simulator will support each of these (and a few more for technical reasons). 
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/puzzle/chapter1/figure2.png&quot; alt=&quot;figure 2&quot; /&gt;&lt;/p&gt;
&lt;div style=&quot;display:flex; margin:1em;&quot;&gt;
    &lt;div style=&quot;flex:33%;&quot;&gt;
        &lt;img src=&quot;http://localhost:4000/assets/puzzle/chapter1/screenshot3a.png&quot; /&gt;
    &lt;/div&gt;
    &lt;div style=&quot;flex:33%;&quot;&gt;
        &lt;img src=&quot;http://localhost:4000/assets/puzzle/chapter1/screenshot3c.png&quot; /&gt;
    &lt;/div&gt;
    &lt;div style=&quot;flex:33%;&quot;&gt;
        &lt;img src=&quot;http://localhost:4000/assets/puzzle/chapter1/screenshot3b.png&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;
Third, some puzzles are ‘deep cut’ and some are ‘shallow cut’. Each face, edge, or vertex that can be twisted has a ‘cutting plane’, or a plane that divides the puzzle into a turning and not-turning region. Increasing the depth of the cutting plane on the puzzle often increases the challenge because deeper cuts produce pieces that can be moved by many different turns. Also, puzzles can be ‘high order’, which means they have multiple parallel cutting planes, such as a 4x4 or 5x5 rubik’s cube as opposed to a 3x3 rubik’s cube.
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/puzzle/chapter1/figure3.png&quot; alt=&quot;figure 3&quot; /&gt;&lt;/p&gt;
&lt;div style=&quot;display:flex; margin:1em;&quot;&gt;
    &lt;div style=&quot;flex:45%;&quot;&gt;
        &lt;img src=&quot;http://localhost:4000/assets/puzzle/chapter1/screenshot2a.png&quot; /&gt;
    &lt;/div&gt;
    &lt;div style=&quot;flex:45%;&quot;&gt;
        &lt;img src=&quot;http://localhost:4000/assets/puzzle/chapter1/screenshot2b.png&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;
Simple puzzles can be defined by their cutting planes and planes that define their shape. A valid set of planes can be uniquely identified by a given set of normal vectors and a scalar depth. The set of normal vectors comes from a solid such as a dodecahedron, octahedron, etc. Sets of planes serve one of two distinct purposes. The volume of the puzzle is bounded by the shape planes, and cut into movable pieces by the cutting planes. Because pieces need to fit into their ending locations after a turn, they can only be rotated around symmetry groups of the solid they belong to. Therefore, cutting planes are always distributed along a symmetry group of the starting solid, with a given depth. Planes that define shape must also have the same symmetry group so that the puzzle does not change shape after it is turned.
If a puzzle defined with some polyhedron’s shape planes is face turning, the cutting planes will be parallel to that shape’s faces. If the puzzle is vertex turning, the cutting planes will be parallel to that shape’s dual solid’s faces. 
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/puzzle/chapter1/figure4.png&quot; alt=&quot;figure 4&quot; /&gt;
&lt;img src=&quot;http://localhost:4000/assets/puzzle/chapter1/picture1.jpg&quot; height=&quot;270px&quot; style=&quot;display:block; margin-left:auto; margin-right:auto;&quot; /&gt;&lt;/p&gt;
&lt;p&gt;
For a puzzle with edge turning, though, calculating the cutting planes can become more difficult. Knowing that a solid and its dual have the same edge-turning cutting planes, aligning the two solids allows a third to be generated. The third solid is the convex hull of the first two solid’s vertices, and its faces are perpendicular to the cutting planes of either edge turning puzzle. 
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/puzzle/chapter1/figure5.png&quot; alt=&quot;figure 5&quot; /&gt;&lt;/p&gt;
&lt;p&gt;
&lt;div style=&quot;display:flex; margin:1em;&quot;&gt;
    &lt;div style=&quot;flex:33%;&quot;&gt;
        &lt;img src=&quot;http://localhost:4000/assets/puzzle/chapter1/screenshot4a.png&quot; /&gt;
    &lt;/div&gt;
    &lt;div style=&quot;flex:33%;&quot;&gt;
        &lt;img src=&quot;http://localhost:4000/assets/puzzle/chapter1/screenshot4b.png&quot; /&gt;
    &lt;/div&gt;
    &lt;div style=&quot;flex:33%;&quot;&gt;
        &lt;img src=&quot;http://localhost:4000/assets/puzzle/chapter1/screenshot4c.png&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;
For tetrahedrons, this is very simple; a regular tetrahedron is its own dual solid, and aligning them this way produces a cube. The cutting planes perpendicular to the faces of a tetrahedron (turning 120 degrees) and the cutting planes perpendicular to the faces of a cube (turning 180 degrees) represent the first set of symmetry groups that may be used together to produce puzzles.
&lt;/p&gt;
&lt;div style=&quot;display:flex; margin:1em;&quot;&gt;
    &lt;div style=&quot;flex:66%;&quot;&gt;
        &lt;img src=&quot;http://localhost:4000/assets/puzzle/chapter1/screenshot5.png&quot; /&gt;
    &lt;/div&gt;
    &lt;div style=&quot;flex:33%;&quot;&gt;
        &lt;img src=&quot;http://localhost:4000/assets/puzzle/chapter1/picture2.jpg&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;
For cubes and octahedrons, the same process produces a different shape, the rhombic dodecahedron. The second set of symmetry groups consists of the cutting planes perpendicular to the faces of a cube (90 degree rotations), the faces of an octahedron (120 degree rotations), and the faces of a rhombic dodecahedron (180 degree rotations).
&lt;/p&gt;
&lt;div style=&quot;display:flex; margin:1em;&quot;&gt;
    &lt;div style=&quot;flex:66%;&quot;&gt;
        &lt;img src=&quot;http://localhost:4000/assets/puzzle/chapter1/screenshot6.png&quot; /&gt;
    &lt;/div&gt;
    &lt;div style=&quot;flex:33%;&quot;&gt;
        &lt;img src=&quot;http://localhost:4000/assets/puzzle/chapter1/picture3.jpg&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;
The final set of symmetry groups comes from the icosahedron (120 degree), dodecahedron (72 degree), and rhombic triacontahedron (180 degree) via the same process.
&lt;/p&gt;
&lt;div style=&quot;display:flex; margin:1em;&quot;&gt;
    &lt;div style=&quot;flex:66%;&quot;&gt;
        &lt;img src=&quot;http://localhost:4000/assets/puzzle/chapter1/screenshot7.png&quot; /&gt;
    &lt;/div&gt;
    &lt;div style=&quot;flex:33%;&quot;&gt;
        &lt;img src=&quot;http://localhost:4000/assets/puzzle/chapter1/picture4.jpg&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html">In order to build an expressive and powerful simulator, the components that differentiate twisting puzzles must be understood. First of all, puzzles are usually regular polyhedra. Puzzles that are spherical or especially irregular are outside the scope of this simulator. Secondly, puzzles are typically either face-turning, edge-turning, or vertex-turning. The simulator will support each of these (and a few more for technical reasons). Third, some puzzles are ‘deep cut’ and some are ‘shallow cut’. Each face, edge, or vertex that can be twisted has a ‘cutting plane’, or a plane that divides the puzzle into a turning and not-turning region. Increasing the depth of the cutting plane on the puzzle often increases the challenge because deeper cuts produce pieces that can be moved by many different turns. Also, puzzles can be ‘high order’, which means they have multiple parallel cutting planes, such as a 4x4 or 5x5 rubik’s cube as opposed to a 3x3 rubik’s cube. Simple puzzles can be defined by their cutting planes and planes that define their shape. A valid set of planes can be uniquely identified by a given set of normal vectors and a scalar depth. The set of normal vectors comes from a solid such as a dodecahedron, octahedron, etc. Sets of planes serve one of two distinct purposes. The volume of the puzzle is bounded by the shape planes, and cut into movable pieces by the cutting planes. Because pieces need to fit into their ending locations after a turn, they can only be rotated around symmetry groups of the solid they belong to. Therefore, cutting planes are always distributed along a symmetry group of the starting solid, with a given depth. Planes that define shape must also have the same symmetry group so that the puzzle does not change shape after it is turned. If a puzzle defined with some polyhedron’s shape planes is face turning, the cutting planes will be parallel to that shape’s faces. If the puzzle is vertex turning, the cutting planes will be parallel to that shape’s dual solid’s faces. For a puzzle with edge turning, though, calculating the cutting planes can become more difficult. Knowing that a solid and its dual have the same edge-turning cutting planes, aligning the two solids allows a third to be generated. The third solid is the convex hull of the first two solid’s vertices, and its faces are perpendicular to the cutting planes of either edge turning puzzle. For tetrahedrons, this is very simple; a regular tetrahedron is its own dual solid, and aligning them this way produces a cube. The cutting planes perpendicular to the faces of a tetrahedron (turning 120 degrees) and the cutting planes perpendicular to the faces of a cube (turning 180 degrees) represent the first set of symmetry groups that may be used together to produce puzzles. For cubes and octahedrons, the same process produces a different shape, the rhombic dodecahedron. The second set of symmetry groups consists of the cutting planes perpendicular to the faces of a cube (90 degree rotations), the faces of an octahedron (120 degree rotations), and the faces of a rhombic dodecahedron (180 degree rotations). The final set of symmetry groups comes from the icosahedron (120 degree), dodecahedron (72 degree), and rhombic triacontahedron (180 degree) via the same process.</summary></entry><entry><title type="html">Rubik’s Puzzle Nuances</title><link href="http://localhost:4000/puzzle/2018/08/13/rubiks-puzzle-nuances.html" rel="alternate" type="text/html" title="Rubik's Puzzle Nuances" /><published>2018-08-13T10:39:54-04:00</published><updated>2018-08-13T10:39:54-04:00</updated><id>http://localhost:4000/puzzle/2018/08/13/rubiks-puzzle-nuances</id><content type="html" xml:base="http://localhost:4000/puzzle/2018/08/13/rubiks-puzzle-nuances.html">&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/puzzle/chapter3/screenshot1.png&quot; alt=&quot;figure 5&quot; /&gt;&lt;/p&gt;
&lt;p&gt;
The generator is able to make truncated shapes very easily. Multiple sets of shape planes can be added, and the puzzle's volume will be bounded by all of them, so adding both a shape and that shape's dual will allow truncated shapes to be added. Both vertex and edge truncations can be done for any of the natural solids.
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/puzzle/chapter3/screenshot2.png&quot; alt=&quot;figure 5&quot; /&gt;&lt;/p&gt;
&lt;p&gt;
The generator is not restricted to creating just edge turning, vertex turning, or face turning puzzles. Hybrids can be made, which twist about multiple types of features. Adding multiple sets of cutting planes allows any combination to be made.
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/puzzle/chapter3/screenshot3.png&quot; alt=&quot;figure 5&quot; /&gt;&lt;/p&gt;
&lt;p&gt;
Higher order puzzles are easy, too. Multiple of the same set of planes can be added with different depths. Stacking cube planes like that creates the '5x5' cube, but the same principle applies to any puzzle.
&lt;/p&gt;
&lt;div style=&quot;display:flex; margin:1em;&quot;&gt;
    &lt;div style=&quot;flex:45%;&quot;&gt;
        &lt;img src=&quot;http://localhost:4000/assets/puzzle/chapter3/screenshot4a.png&quot; /&gt;
    &lt;/div&gt;
    &lt;div style=&quot;flex:45%;&quot;&gt;
        &lt;img src=&quot;http://localhost:4000/assets/puzzle/chapter3/screenshot4b.png&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;
While all cutting planes must come from compatable symmetry groups, shape planes do not have this restriction. In this example, the dodecahedron can be scrambled with tetrahedron cutting planes and still stay the same shape, because tetrahedron cutting planes line up with icosahedron cutting planes.
&lt;/p&gt;
&lt;div style=&quot;display:flex; margin:1em;&quot;&gt;
    &lt;div style=&quot;flex:45%;&quot;&gt;
        &lt;img src=&quot;http://localhost:4000/assets/puzzle/chapter3/screenshot5a.png&quot; /&gt;
    &lt;/div&gt;
    &lt;div style=&quot;flex:45%;&quot;&gt;
        &lt;img src=&quot;http://localhost:4000/assets/puzzle/chapter3/screenshot5b.png&quot; /&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;
Not all combinations of shape and cutting planes have that property. Some change shape when scrambled, but there's nothing wrong with that- there are puzzles for sale in real life that behave this way.
&lt;/p&gt;</content><author><name></name></author><summary type="html">The generator is able to make truncated shapes very easily. Multiple sets of shape planes can be added, and the puzzle's volume will be bounded by all of them, so adding both a shape and that shape's dual will allow truncated shapes to be added. Both vertex and edge truncations can be done for any of the natural solids. The generator is not restricted to creating just edge turning, vertex turning, or face turning puzzles. Hybrids can be made, which twist about multiple types of features. Adding multiple sets of cutting planes allows any combination to be made. Higher order puzzles are easy, too. Multiple of the same set of planes can be added with different depths. Stacking cube planes like that creates the '5x5' cube, but the same principle applies to any puzzle. While all cutting planes must come from compatable symmetry groups, shape planes do not have this restriction. In this example, the dodecahedron can be scrambled with tetrahedron cutting planes and still stay the same shape, because tetrahedron cutting planes line up with icosahedron cutting planes. Not all combinations of shape and cutting planes have that property. Some change shape when scrambled, but there's nothing wrong with that- there are puzzles for sale in real life that behave this way.</summary></entry><entry><title type="html">Generating Rubik’s Puzzles</title><link href="http://localhost:4000/puzzle/2018/08/13/generating-rubiks-puzzles.html" rel="alternate" type="text/html" title="Generating Rubik's Puzzles" /><published>2018-08-13T10:39:54-04:00</published><updated>2018-08-13T10:39:54-04:00</updated><id>http://localhost:4000/puzzle/2018/08/13/generating-rubiks-puzzles</id><content type="html" xml:base="http://localhost:4000/puzzle/2018/08/13/generating-rubiks-puzzles.html">&lt;p&gt;
The next step for the cube generator is creating the puzzle’s visible mesh. This is done with the following process:
First, each unique combination of three planes is intersected to create a vertex. This is the simplest step- it only takes some creative iteration and solving a matrix. Each vertex must remember the set of three planes created it. 
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/puzzle/chapter2/figure1.png&quot; alt=&quot;figure 1&quot; /&gt;&lt;/p&gt;
&lt;p&gt;
Second, vertices that are close together are merged. Shapes like the cube and tetrahedron don’t have to worry about this, but shapes like the octahedron and icosahedron have vertices that lie at the intersection of four or more planes, generating many duplicate vertices. Even the dodecahedron planes will create duplicate vertices, but those vertices lie outside the solid, so they only become relevant when those planes are cutting planes, not shape-defining planes. This part began to create performance issues, because N planes would create (n)(n-1)(n-3)/6 vertices, and V vertices would necessitate (v)(v-1)/2 duplicate checks. To improve the algorithm’s time complexity, I sorted the vertices by their x value first, and then used a creative iteration method to eliminate the vast majority of duplicate vertex checks. If two vertices are merged, the resulting vertex’s set of planes will be the union of the two that merged. 
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/puzzle/chapter2/figure2.png&quot; alt=&quot;figure 2&quot; /&gt;&lt;/p&gt;
&lt;p&gt;
Third, each vertex must determine which side of each plane it lies on. This can be done easily in this scenario, because it turns into one dot product. Vertices are not tested against the planes that created them. If a vertex lies on the outside of a shape-defining plane, it will be eliminated. Vertices remember which cutting planes they lie outside of. 
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/puzzle/chapter2/figure3.png&quot; alt=&quot;figure 3&quot; /&gt;&lt;/p&gt;
&lt;p&gt;
Fourth, the vertices are sorted into different containers, each container representing an indivisible piece of the puzzle. Shape planes don’t factor into this sorting process, but cutting planes do. If a puzzle has no cutting planes, then all vertices would fall into a single container. Each cutting plane multiplies the number of containers by two. Each container is divided into a container above the cutting plane, which rotates when that face is turned, and a container below it which does not. If a vertex lies above or below a cutting plane, that determines which container it falls into. If it was created by the cutting plane and therefore lies on that plane, then the vertex is duplicated and goes into both containers. 
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/puzzle/chapter2/figure4.png&quot; alt=&quot;figure 4&quot; /&gt;&lt;/p&gt;
&lt;p&gt;
Lastly, each container is stitched together to create its visible mesh. Faces are identified as non-exclusive groups of vertices that were created by the same plane. Cross and dot products are then used to sort them with the correct winding order. If the plane that created these vertices was a shape defining plane, a copy of the face vertices are made and then scaled inwards to serve as the colored part of the mesh. 
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/puzzle/chapter2/figure5.png&quot; alt=&quot;figure 5&quot; /&gt;&lt;/p&gt;
&lt;p&gt;
The rest of the application isn't as interesting from a mathematical point of view. Pieces of the puzzle can be dragged to rotate, or spheres can be clicked to rotate a face once. Pieces rotate if their centers lie above the cutting plane that was 'activated'.
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/puzzle/chapter2/screenshot1.png&quot; alt=&quot;screenshot 1&quot; /&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">The next step for the cube generator is creating the puzzle’s visible mesh. This is done with the following process: First, each unique combination of three planes is intersected to create a vertex. This is the simplest step- it only takes some creative iteration and solving a matrix. Each vertex must remember the set of three planes created it. Second, vertices that are close together are merged. Shapes like the cube and tetrahedron don’t have to worry about this, but shapes like the octahedron and icosahedron have vertices that lie at the intersection of four or more planes, generating many duplicate vertices. Even the dodecahedron planes will create duplicate vertices, but those vertices lie outside the solid, so they only become relevant when those planes are cutting planes, not shape-defining planes. This part began to create performance issues, because N planes would create (n)(n-1)(n-3)/6 vertices, and V vertices would necessitate (v)(v-1)/2 duplicate checks. To improve the algorithm’s time complexity, I sorted the vertices by their x value first, and then used a creative iteration method to eliminate the vast majority of duplicate vertex checks. If two vertices are merged, the resulting vertex’s set of planes will be the union of the two that merged. Third, each vertex must determine which side of each plane it lies on. This can be done easily in this scenario, because it turns into one dot product. Vertices are not tested against the planes that created them. If a vertex lies on the outside of a shape-defining plane, it will be eliminated. Vertices remember which cutting planes they lie outside of. Fourth, the vertices are sorted into different containers, each container representing an indivisible piece of the puzzle. Shape planes don’t factor into this sorting process, but cutting planes do. If a puzzle has no cutting planes, then all vertices would fall into a single container. Each cutting plane multiplies the number of containers by two. Each container is divided into a container above the cutting plane, which rotates when that face is turned, and a container below it which does not. If a vertex lies above or below a cutting plane, that determines which container it falls into. If it was created by the cutting plane and therefore lies on that plane, then the vertex is duplicated and goes into both containers. Lastly, each container is stitched together to create its visible mesh. Faces are identified as non-exclusive groups of vertices that were created by the same plane. Cross and dot products are then used to sort them with the correct winding order. If the plane that created these vertices was a shape defining plane, a copy of the face vertices are made and then scaled inwards to serve as the colored part of the mesh. The rest of the application isn't as interesting from a mathematical point of view. Pieces of the puzzle can be dragged to rotate, or spheres can be clicked to rotate a face once. Pieces rotate if their centers lie above the cutting plane that was 'activated'.</summary></entry><entry><title type="html">Generating Interesting Isosurfaces</title><link href="http://localhost:4000/voxel/2018/08/13/generating-interesting-isosurfaces.html" rel="alternate" type="text/html" title="Generating Interesting Isosurfaces" /><published>2018-08-13T10:39:54-04:00</published><updated>2018-08-13T10:39:54-04:00</updated><id>http://localhost:4000/voxel/2018/08/13/generating-interesting-isosurfaces</id><content type="html" xml:base="http://localhost:4000/voxel/2018/08/13/generating-interesting-isosurfaces.html">&lt;p&gt;
- Now that we have a reliable way to sample and render isosurfaces, we need some interesting isosurfaces to render. Most good methods start with a base of some volumetric noise combined with the voxel’s vertical coordinate. I’m generating multiple different 3d samplers filled with random noise, and adding them together with different frequencies and amplitudes just like perlin noise for my volumetric noise function. I’m just doing linear interpolation, though, and its a fascinating thing because the interpolation method I’m using is clearly visible in the generated mesh. (See the attached example) the flatish parts that clearly change direction at each grid point is very distinctive of linear interpolation. In addition to subtracting the voxel’s vertical coordinate, I also subtract the voxel’s vertical coordinate truncate divided by 16 and then multiplied by 16 to give it those shelf-looking features. Because I’m not seeding the pseudorandom number generator, and I haven’t changed the generation algorithm much since ive started, ive become very familiar with the valley structure pictured.
&lt;/p&gt;</content><author><name></name></author><summary type="html">- Now that we have a reliable way to sample and render isosurfaces, we need some interesting isosurfaces to render. Most good methods start with a base of some volumetric noise combined with the voxel’s vertical coordinate. I’m generating multiple different 3d samplers filled with random noise, and adding them together with different frequencies and amplitudes just like perlin noise for my volumetric noise function. I’m just doing linear interpolation, though, and its a fascinating thing because the interpolation method I’m using is clearly visible in the generated mesh. (See the attached example) the flatish parts that clearly change direction at each grid point is very distinctive of linear interpolation. In addition to subtracting the voxel’s vertical coordinate, I also subtract the voxel’s vertical coordinate truncate divided by 16 and then multiplied by 16 to give it those shelf-looking features. Because I’m not seeding the pseudorandom number generator, and I haven’t changed the generation algorithm much since ive started, ive become very familiar with the valley structure pictured.</summary></entry><entry><title type="html">Breadboard computer overview</title><link href="http://localhost:4000/breadboard/2018/08/13/breadboard-computer-overview.html" rel="alternate" type="text/html" title="Breadboard computer overview" /><published>2018-08-13T10:39:54-04:00</published><updated>2018-08-13T10:39:54-04:00</updated><id>http://localhost:4000/breadboard/2018/08/13/breadboard-computer-overview</id><content type="html" xml:base="http://localhost:4000/breadboard/2018/08/13/breadboard-computer-overview.html">&lt;p&gt;
The computer is broken down into different modules that are connected to each other mostly via the bus.
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/breadboard/chapter1/figure1.png&quot; alt=&quot;figure 1&quot; /&gt;&lt;/p&gt;
&lt;p&gt;
My power supply is just a usb 5v power cable that I cut and soldered to breadboard wires. It works fine.
My clock is built from the schematic below. I swap out the capacitor to adjust the speed of the clock. [elaborate] The clock outputs a square wave that keeps the computer going.
Buffers are designed to store one binary word. This is how data is manipulated within the computer- binary operands are stored in buffers A and B so that the bus can be used to place the result of the operation in another location. The address buffer is the same- used for dereferencing pointers. The C buffer, on the other hand, is used for shuffling around data and debugging. Then, there’s the instruction buffer, used for storing the current instruction that is to be executed. 
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/breadboard/chapter1/figure2.png&quot; alt=&quot;figure 2&quot; /&gt;&lt;/p&gt;
&lt;p&gt;
The multiplexer is used to switch between accessing the portion of ram addressed by the instruction counter and accessing the portion of ram addressed by the address buffer. This is integral to the operation of the computer; sometimes it needs to access instructions and sometimes it needs to dereference pointers, but both operate on the same ram. 
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/breadboard/chapter1/figure3.png&quot; alt=&quot;figure 3&quot; /&gt;&lt;/p&gt;
&lt;p&gt;
The bus is an important concept for the computer. The bus is what allows the computer to arbitrarily move information between different buffers. In other parts of the computer, each wire has an input and one or more outputs. The bus, though, has many inputs and many outputs. At any one time, only one component is outputting to the bus and only one component is accepting input from the bus. The ram and c buffer can input to or output from the ram, but most components only listen to the bus. components can selectively output with tristate buffers- outputs can be high, low, or high impedance.
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/breadboard/chapter1/figure4.png&quot; alt=&quot;figure 4&quot; /&gt;&lt;/p&gt;
&lt;p&gt;
Even though the computer is completely self-sufficient, I do have a raspberry PI connected to the bus for the purpose of testing and initialization. When the computer is started, I run a program on the raspberry PI to initialize the computer’s ram to a given set of instructions. To do this, the PI also has outputs that let it temporarily override the computer’s state and control its clock and instruction counter. Ram is set to input, multiplexer is set to listen to the instruction counter, and then the instruction counter counts while the PI sequentially reads the computer’s instructions onto the bus, populating the computer’s ram. Once that is finished, the instruction counter should be initialized to the location of the first instruction in memory. For my computer, that is always 0. 
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/breadboard/chapter1/figure5.png&quot; alt=&quot;figure 5&quot; /&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">The computer is broken down into different modules that are connected to each other mostly via the bus. My power supply is just a usb 5v power cable that I cut and soldered to breadboard wires. It works fine. My clock is built from the schematic below. I swap out the capacitor to adjust the speed of the clock. [elaborate] The clock outputs a square wave that keeps the computer going. Buffers are designed to store one binary word. This is how data is manipulated within the computer- binary operands are stored in buffers A and B so that the bus can be used to place the result of the operation in another location. The address buffer is the same- used for dereferencing pointers. The C buffer, on the other hand, is used for shuffling around data and debugging. Then, there’s the instruction buffer, used for storing the current instruction that is to be executed. The multiplexer is used to switch between accessing the portion of ram addressed by the instruction counter and accessing the portion of ram addressed by the address buffer. This is integral to the operation of the computer; sometimes it needs to access instructions and sometimes it needs to dereference pointers, but both operate on the same ram. The bus is an important concept for the computer. The bus is what allows the computer to arbitrarily move information between different buffers. In other parts of the computer, each wire has an input and one or more outputs. The bus, though, has many inputs and many outputs. At any one time, only one component is outputting to the bus and only one component is accepting input from the bus. The ram and c buffer can input to or output from the ram, but most components only listen to the bus. components can selectively output with tristate buffers- outputs can be high, low, or high impedance. Even though the computer is completely self-sufficient, I do have a raspberry PI connected to the bus for the purpose of testing and initialization. When the computer is started, I run a program on the raspberry PI to initialize the computer’s ram to a given set of instructions. To do this, the PI also has outputs that let it temporarily override the computer’s state and control its clock and instruction counter. Ram is set to input, multiplexer is set to listen to the instruction counter, and then the instruction counter counts while the PI sequentially reads the computer’s instructions onto the bus, populating the computer’s ram. Once that is finished, the instruction counter should be initialized to the location of the first instruction in memory. For my computer, that is always 0.</summary></entry><entry><title type="html">Breadboard computer operations</title><link href="http://localhost:4000/breadboard/2018/08/13/breadboard-computer-operations.html" rel="alternate" type="text/html" title="Breadboard computer operations" /><published>2018-08-13T10:39:54-04:00</published><updated>2018-08-13T10:39:54-04:00</updated><id>http://localhost:4000/breadboard/2018/08/13/breadboard-computer-operations</id><content type="html" xml:base="http://localhost:4000/breadboard/2018/08/13/breadboard-computer-operations.html">&lt;p&gt;
I planned to support a limited but easily Turing-complete opset, settling on the following list of operations for the breadboard computer:
&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;
	SET: sets a given buffer (not ram) to the word after the current instruction, and then skips over it to avoid interpreting the word as an instruction.
	&lt;/li&gt;
	&lt;li&gt;
	MOV: moves a word from one buffer to another, or from a buffer to ram at the address pointed to by the address buffer, or from ram at the address pointed to by the address buffer to a buffer.
	&lt;/li&gt;
	&lt;li&gt;
	ALU: performs an indicated operation on buffers A and B and stores the output in a designated location.
	&lt;/li&gt;
	&lt;li&gt;
	SKP: selects an indicated buffer (or ram) and skips the next operation only if that buffer is non-zero.
	&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
To select a buffer to input to or output from, two decoders are used. Decoders accept some binary input and ‘select’ one output to be held high while the other outputs are held low. One decoder is used to select an input and another decoder is used for outputs.
Instructions are interpreted the following way:
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/breadboard/chapter2/figure1.png&quot; alt=&quot;figure 1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;
It is important to note the lack of a JMP instruction. This is because the computer achieves this by having the instruction counter as a possible input. This way, the computer can use a SET instruction to jump to a predefined location in the instructions, or a MOV instruction to get a location from RAM or the C buffer and jump to a computed location.
The phase counter is a counter that I use to segment each instruction into four stages. The counter counts to four in binary, increasing by one each time it gets an input, and resetting once it reaches four. Each different number on the counter puts the machine in a different stage. The first and second stages are simple because they are the same for each different instruction, but the third and fourth depend on the instruction that the machine is currently on. 
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/breadboard/chapter2/figure2.png&quot; alt=&quot;figure 2&quot; /&gt;&lt;/p&gt;
&lt;p&gt;
On the first stage, the machine sets the multiplexer to listen to the instruction counter, sets the RAM to output, and sets the instruction buffer to read. This effectively reads the current address into the instruction buffer.
On the second stage, the machine increases the instruction buffer.
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/breadboard/chapter2/figure3.png&quot; alt=&quot;figure 3&quot; /&gt;&lt;/p&gt;
&lt;p&gt;
The instruction buffer then differentiates the next two stages.
&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;
	For the SET operation, the third phase keeps the multiplexer listening to the instruction counter and sets the ram to output. The input decoder is used to determine the buffer that will be set to input. The fourth phase increments the instruction counter once more. 
	&lt;img src=&quot;http://localhost:4000/assets/breadboard/chapter2/figure4.png&quot; /&gt;
	&lt;/li&gt;
	&lt;li&gt;
	For the MOV operation during the third phase, the output decoder is used to determine which buffer (or ram) will be set to output, and the input decoder is used to determine which buffer (or ram) will be set to input. The multiplexer will be listening to the address buffer during this phase. The fourth phase is empty. 
	&lt;img src=&quot;http://localhost:4000/assets/breadboard/chapter2/figure5.png&quot; /&gt;
	&lt;/li&gt;
	&lt;li&gt;
	The ALU operation uses the output decoder to determine which operation to tell the ALU to perform, and the input decoder to determine which buffer (or ram) to set to input. The fourth phase is empty. 
	&lt;img src=&quot;http://localhost:4000/assets/breadboard/chapter2/figure6.png&quot; /&gt;
	&lt;/li&gt;
	&lt;li&gt;
	During its third phase, the SKP operation uses the output decoder to determine which buffer (or ram) to set to output, and the rs-nor latch is set to input. During fourth phase, the instruction counter is incremented if the nor latch is high. 
	&lt;img src=&quot;http://localhost:4000/assets/breadboard/chapter2/figure7.png&quot; /&gt;
	&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
It is important to note that no matter the instruction, the bus is only used during the first and third phases, while the second and fourth are used for incrementing the instruction buffer only. Though I never got around to it, this was so that the machine could have two cores. Since both cores only touch the bus on thpeir first and third phases, they could coexist if one’s even phase lined up with the other’s odd phase. Each core would have its own instruction counter, instruction buffer, input/output decoders, address buffer, conditional skip latch, and its own A,B, and C buffers. A hefty number of multiplexers would need to be in place to switch between each set of buffers to select which core was interacting with the bus. Even just one core quickly became a large undertaking, though, so I let the two core design stay an idea. This idea is implemented in modern cpus as [][][][]. 
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/breadboard/chapter2/figure8.png&quot; alt=&quot;figure 5&quot; /&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">I planned to support a limited but easily Turing-complete opset, settling on the following list of operations for the breadboard computer: SET: sets a given buffer (not ram) to the word after the current instruction, and then skips over it to avoid interpreting the word as an instruction. MOV: moves a word from one buffer to another, or from a buffer to ram at the address pointed to by the address buffer, or from ram at the address pointed to by the address buffer to a buffer. ALU: performs an indicated operation on buffers A and B and stores the output in a designated location. SKP: selects an indicated buffer (or ram) and skips the next operation only if that buffer is non-zero. To select a buffer to input to or output from, two decoders are used. Decoders accept some binary input and ‘select’ one output to be held high while the other outputs are held low. One decoder is used to select an input and another decoder is used for outputs. Instructions are interpreted the following way:</summary></entry></feed>